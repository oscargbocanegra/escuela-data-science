{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e443dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando las librerias para el ejercicio.\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import IntegerType, StringType, FloatType\n",
    "from pyspark.sql.types import Row\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23b0777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando el contexto que funciona como punto de conexion para todo spark.\n",
    "spark = SparkContext(master=\"local\", appName=\"DataFrames\")\n",
    "sqlContext = SQLContext(spark)\n",
    "\n",
    "# Creando una variable que guarde la ruta de los archivos de datos.\n",
    "path = \"/home/jovyan/work/files/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3112218",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Consultando la ruta para ubicar los archivos.\n",
    "!ls /home/jovyan/work/files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8006f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicando lectura para cargar el archivo.\n",
    "juegoDF = sqlContext.read.schema(juegoSchema).option(\"header\",\"true\").csv(path + \"juegos.csv\")\n",
    "\n",
    "# Visualizando el dataframe con show().\n",
    "juegoDF.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fe5c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando DataFrames de archivos .data\n",
    "autoDataRDD = spark.textFile(path+\"auto-mpg.data\").map(lambda l : l.replace(\"\\\\s\",\"\"))\n",
    "imports85RDD = spark.textFile(path+\"imports-85.data\").map(lambda l : l.replace(\"\\\\s\",\"\"))\n",
    "synthetic_controlRDD = spark.textFile(path+\"synthetic_control.data\").map(lambda l : l.replace(\"\\\\s\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950f4cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando funcion para eliminar encabezados\n",
    "def eliminaEncabezado(indice, iterador):\n",
    "    return iter(list(iterador)[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853e1015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando el Dataframes a partir de los RDD correspondiente al archivo deportista.csv.\n",
    "deportistaOlimpicoRDD = spark.textFile(path+\"deportista.csv\").map(lambda l : l.split(\",\"))\n",
    "\n",
    "# Pasando El RDD a la funcion creada para eliminar el encabezado.\n",
    "deportistaOlimpicoRDD = deportistaOlimpicoRDD.mapPartitionsWithIndex(eliminaEncabezado)\n",
    "\n",
    "# Transformando los valores del RDD.\n",
    "deportistaOlimpicoRDD = deportistaOlimpicoRDD.map(lambda l : (\n",
    "int(l[0]),\n",
    "l[1],\n",
    "int(l[2]),\n",
    "int(l[3]),\n",
    "int(l[4]),\n",
    "float(l[5]),\n",
    "int(l[6])\n",
    "))\n",
    "\n",
    "# Creando el Schema para los campos del RDD\n",
    "schemadeportistaOlimpicoRDD = StructType([\n",
    "    StructField(\"deportista_id\",IntegerType(),False),\n",
    "    StructField(\"nombre\",StringType(),False),\n",
    "    StructField(\"genero\",IntegerType(),False),\n",
    "    StructField(\"edad\",IntegerType(),False),\n",
    "    StructField(\"altura\",IntegerType(),False),\n",
    "    StructField(\"peso\",FloatType(),False),\n",
    "    StructField(\"equipo_id\",IntegerType(),False)\n",
    "])\n",
    "\n",
    "# Visualizando la transformación del Dataframe deportistaDF.\n",
    "deportistaDF = sqlContext.createDataFrame(deportistaOlimpicoRDD,schemadeportistaOlimpicoRDD).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eec332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando el Dataframes a partir de los RDD correspondiente al archivo data.csv\n",
    "dataRDD = spark.textFile(path+\"data.csv\").map(lambda l : l.split(\",\"))\n",
    "\n",
    "# Pasando El RDD a la funcion creada para eliminar el encabezado.\n",
    "dataRDD = dataRDD.mapPartitionsWithIndex(eliminaEncabezado)\n",
    "\n",
    "# Transformando los valores del RDD.\n",
    "dataRDD = dataRDD.map(lambda l : (\n",
    "l[0],\n",
    "l[1],\n",
    "int(l[2])\n",
    "))\n",
    "\n",
    "# Creando Schema para los campos del RDD.\n",
    "schemadataRDD = StructType([\n",
    "    StructField(\"Estado\",StringType(),False),\n",
    "    StructField(\"color\",StringType(),False),\n",
    "    StructField(\"contador\",IntegerType(),False)\n",
    "])\n",
    "\n",
    "# Visualizando la transformación del Dataframe.\n",
    "dataDF = sqlContext.createDataFrame(dataRDD,schemadataRDD).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb452a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando el Dataframes a partir de los RDD correspondiente al archivo deporte.csv\n",
    "deporteRDD = spark.textFile(path+\"deporte.csv\").map(lambda l : l.split(\",\"))\n",
    "\n",
    "# Pasando El RDD a la funcion creada para eliminar el encabezado.\n",
    "deporteRDD = deporteRDD.mapPartitionsWithIndex(eliminaEncabezado)\n",
    "\n",
    "# Transformando los valores del RDD.\n",
    "deporteRDD = deporteRDD.map(lambda l : (\n",
    "int(l[0]),\n",
    "l[1]\n",
    "))\n",
    "\n",
    "# Creando Schema para los campos del RDD.\n",
    "schema_deporteRDD = StructType([\n",
    "    StructField(\"deporte_ID\",IntegerType(),False),\n",
    "    StructField(\"deporte\",StringType(),False)\n",
    "])\n",
    "\n",
    "# Visualizando la transformación del Dataframe.\n",
    "deporteRDD = sqlContext.createDataFrame(deporteRDD,schema_deporteRDD).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be52e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando el Dataframes a partir de los RDD correspondiente al archivo deportista2.csv\n",
    "deportista2RDD = spark.textFile(path+\"deportista2.csv\").map(lambda l : l.split(\",\"))\n",
    "\n",
    "# Pasando El RDD a la funcion creada para eliminar el encabezado.\n",
    "deportista2RDD = deportista2RDD.mapPartitionsWithIndex(eliminaEncabezado)\n",
    "\n",
    "# Transformando los valores del RDD.\n",
    "deportista2RDD = deportista2RDD.map(lambda l : (\n",
    "int(l[0]),\n",
    "l[1],\n",
    "int(l[2]),\n",
    "int(l[3]),\n",
    "int(l[4]),\n",
    "float(l[5]),\n",
    "int(l[6])\n",
    "))\n",
    "\n",
    "# Creando Schema para los campos del RDD.\n",
    "schema_deportista2RDD = StructType([\n",
    "    StructField(\"deportista_id\",IntegerType(),False),\n",
    "    StructField(\"nombre\",StringType(),False),\n",
    "    StructField(\"genero\",IntegerType(),False),\n",
    "    StructField(\"edad\",IntegerType(),False),\n",
    "    StructField(\"altura\",IntegerType(),False),\n",
    "    StructField(\"peso\",FloatType(),False),\n",
    "    StructField(\"equipo_id\",IntegerType(),False)\n",
    "])\n",
    "\n",
    "# Visualizando la transformación del Dataframe.\n",
    "deportista2RDD = sqlContext.createDataFrame(deportista2RDD,schema_deportista2RDD).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bd79dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando el Dataframes a partir de los RDD correspondiente al archivo evento.csv\n",
    "eventoRDD = spark.textFile(path+\"evento.csv\").map(lambda l : l.split(\",\"))\n",
    "\n",
    "# Pasando El RDD a la funcion creada para eliminar el encabezado.\n",
    "eventoRDD = eventoRDD.mapPartitionsWithIndex(eliminaEncabezado)\n",
    "\n",
    "# Transformando los valores del RDD.\n",
    "eventoRDD = eventoRDD.map(lambda l : (\n",
    "int(l[0]),\n",
    "l[1],\n",
    "l[2]\n",
    "))\n",
    "\n",
    "# Creando Schema para los campos del RDD.\n",
    "schema_eventoRDD = StructType([\n",
    "    StructField(\"id_evento\",IntegerType(),False),\n",
    "    StructField(\"tipo_evento\",StringType(),False),\n",
    "    StructField(\"id_deporte\",StringType(),False)\n",
    "])\n",
    "# Visualizando la transformación del Dataframe.\n",
    "eventoRDD = sqlContext.createDataFrame(eventoRDD,schema_eventoRDD).show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b562b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando el Dataframes a partir de los RDD correspondiente al archivo juegos.csv\n",
    "juegosRDD = spark.textFile(path+\"juegos.csv\").map(lambda l : l.split(\",\"))\n",
    "\n",
    "# Pasando El RDD a la funcion creada para eliminar el encabezado\n",
    "juegosRDD = juegosRDD.mapPartitionsWithIndex(eliminaEncabezado)\n",
    "\n",
    "# Transformando los valores del RDD.\n",
    "juegosRDD = juegosRDD.map(lambda l : (\n",
    "int(l[0]),\n",
    "l[1],\n",
    "int(l[2]),\n",
    "l[3],\n",
    "l[4]\n",
    "))\n",
    "\n",
    "# Creando Schema para los campos del RDD.\n",
    "Schema_juegosRDD = StructType([\n",
    "    StructField(\"juego_id\", IntegerType(),False),\n",
    "    StructField(\"nombre_juego\", StringType(),False),\n",
    "    StructField(\"anio\", IntegerType(),False),\n",
    "    StructField(\"temporada\", StringType(),False),\n",
    "    StructField(\"ciudad\", StringType(),False)\n",
    "])\n",
    "\n",
    "# Visualizando la transformación del Dataframe.\n",
    "juegosRDD = sqlContext.createDataFrame(juegosRDD,Schema_juegosRDD).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b53c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando el Dataframes a partir de los RDD correspondiente al archivo paises.csv\n",
    "paisesRDD = spark.textFile(path+\"paises.csv\").map(lambda l : l.split(\",\"))\n",
    "\n",
    "# Pasando El RDD a la funcion creada para eliminar el encabezado\n",
    "paisesRDD = paisesRDD.mapPartitionsWithIndex(eliminaEncabezado)\n",
    "\n",
    "# Transformando los valores del RDD.\n",
    "paisesRDD = paisesRDD.map(lambda l : (\n",
    "int(l[0]),\n",
    "l[1],\n",
    "l[2]\n",
    "))\n",
    "\n",
    "# Creando Schema para los campos del RDD.\n",
    "Schema_paisesRDD = StructType([\n",
    "    StructField(\"pais_id\", IntegerType(),False),\n",
    "    StructField(\"nombre_equipo\", StringType(),False),\n",
    "    StructField(\"sigla_equipo\", StringType(),False)\n",
    "])\n",
    "\n",
    "# Visualizando la transformación del Dataframe.\n",
    "paisesRDD = sqlContext.createDataFrame(paisesRDD,Schema_paisesRDD).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ac97d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando el Dataframes a partir de los RDD correspondiente al archivo resultados.csv\n",
    "resultadosRDD = spark.textFile(path+\"resultados.csv\").map(lambda l : l.split(\",\"))\n",
    "\n",
    "# Pasando El RDD a la funcion creada para eliminar el encabezado\n",
    "resultadosRDD = resultadosRDD.mapPartitionsWithIndex(eliminaEncabezado)\n",
    "\n",
    "# Transformando los valores del RDD.\n",
    "resultadosRDD = resultadosRDD.map(lambda l : (\n",
    "int(l[0]),\n",
    "l[1],\n",
    "int(l[2]),\n",
    "int(l[3]),\n",
    "int(l[4])\n",
    "))\n",
    "\n",
    "# Creando Schema para los campos del RDD.\n",
    "schema_resultadosRDD = StructType([\n",
    "    StructField(\"resultado_id\",IntegerType(),False),\n",
    "    StructField(\"medalla\",StringType(),False),\n",
    "    StructField(\"deportista_id\",IntegerType(),False),\n",
    "    StructField(\"juego_id\",IntegerType(),False),\n",
    "    StructField(\"evento_id\",IntegerType(),False)\n",
    "])\n",
    "\n",
    "# Visualizando la transformación del Dataframe.\n",
    "resultadosRDD = sqlContext.createDataFrame(resultadosRDD,schema_resultadosRDD).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a479981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2cfc6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fb00b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658548e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec9d4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
